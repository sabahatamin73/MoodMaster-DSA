{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = pd.read_csv(\"./Datasets/Tweets_Train.csv\")\n",
    "test = pd.read_csv(\"./Datasets/Tweets_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@virginamerica what @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@virginamerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@virginamerica i didn't today... must mean i n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@virginamerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@virginamerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               text\n",
       "0   neutral                @virginamerica what @dhepburn said.\n",
       "1  positive  @virginamerica plus you've added commercials t...\n",
       "2   neutral  @virginamerica i didn't today... must mean i n...\n",
       "3  negative  @virginamerica it's really aggressive to blast...\n",
       "4  negative  @virginamerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained['text'] = trained['text'].str.lower()\n",
    "test['text'] = test['text'].str.lower()\n",
    "trained.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"i'm\", 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the stopwords\n",
    "stopwords = []\n",
    "\n",
    "# Open the stopwords.txt file in read mode\n",
    "with open(\"./Stopwords/stopwords.txt\", \"r\") as file:\n",
    "    # Loop over each line in the file\n",
    "    for every_line in file:\n",
    "        # Loop over each word in the current line\n",
    "        for word in every_line.split():\n",
    "            # Add the current word to the stopwords list\n",
    "            stopwords.append(word)\n",
    "\n",
    "# Print the list of stopwords to the console\n",
    "print(stopwords)\n",
    "\n",
    "#List of all special characters that are to be removed.\n",
    "special_chars = [\"!\",'\"',\"%\",\"&\",\"amp\",\"'\",\"(\",\")\", \"*\",\"+\",\",\",\"-\",\".\",\n",
    "                 \"/\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"[\",\"\\\"\",\"]\",\"^\",\"_\",\n",
    "                 \"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\",\"@\",\"#\",\"$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@virginamerica @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@virginamerica plus added commercials experien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@virginamerica today... must mean need take an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@virginamerica really aggressive blast obnoxio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               text\n",
       "0   neutral                     @virginamerica @dhepburn said.\n",
       "1  positive  @virginamerica plus added commercials experien...\n",
       "2   neutral  @virginamerica today... must mean need take an...\n",
       "3  negative  @virginamerica really aggressive blast obnoxio...\n",
       "4  negative                @virginamerica really big bad thing"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop over each index in the \"text\" column of the \"trained\" dataframe\n",
    "for i in range(len(trained['text'])):\n",
    "    # Create an empty string to store the cleaned version of the current text\n",
    "    new = \"\"\n",
    "    # Split the current text into a list of words\n",
    "    temp = trained['text'][i].split(\" \")\n",
    "    # Loop over each word in the list of words\n",
    "    for j in temp:\n",
    "        # If the current word is not in the stopwords list\n",
    "        if j not in stopwords:\n",
    "            # Add the current word and a space to the new string\n",
    "            new += j + \" \"\n",
    "    # Set the current text in the \"trained\" dataframe to the cleaned version of the text (excluding the last space)\n",
    "    trained['text'][i] = new[:-1]\n",
    "\n",
    "# Print the first few rows of the \"trained\" dataframe to the console\n",
    "trained.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EAM\\AppData\\Local\\Temp\\ipykernel_4920\\59959476.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['text'][i] = new[:-1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@usairways phl, btv today made deplane \"it's s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@usairways things non-delayed flights na? get ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@usairways today,no reason 4 anyone approve me...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@usairways look better service.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@usairways customer service philly deplorable,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               text  Predicted\n",
       "0  negative  @usairways phl, btv today made deplane \"it's s...        NaN\n",
       "1  negative  @usairways things non-delayed flights na? get ...        NaN\n",
       "2  negative  @usairways today,no reason 4 anyone approve me...        NaN\n",
       "3   neutral                    @usairways look better service.        NaN\n",
       "4  negative  @usairways customer service philly deplorable,...        NaN"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop over each index in the \"text\" column of the \"test\" dataframe\n",
    "for i in range(len(test['text'])):\n",
    "    # Create an empty string to store the cleaned version of the current text\n",
    "    new = \"\"\n",
    "    # Split the current text into a list of words\n",
    "    temp = test['text'][i].split(\" \")\n",
    "    # Loop over each word in the list of words\n",
    "    for j in temp:\n",
    "        # If the current word is not in the stopwords list\n",
    "        if j not in stopwords:\n",
    "            # Add the current word and a space to the new string\n",
    "            new += j + \" \"\n",
    "    # Set the current text in the \"test\" dataframe to the cleaned version of the text (excluding the last space)\n",
    "    test['text'][i] = new[:-1]\n",
    "\n",
    "# Print the first few rows of the \"test\" dataframe to the console\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing hyperlinks from all the tweets\n",
    "trained['text'] = trained['text'].str.replace(r'http?://[^\\s<>\"]+|www\\.[^\\s<>\"]+', '', regex=True)\n",
    "# Removing usernames from all the tweets\n",
    "trained['text'] = trained['text'].str.replace('@[A-Za-z0-9]+', '', regex=True)\n",
    "# Removing hashtags, including the text, from all the tweets\n",
    "trained['text'] = trained['text'].str.replace(r'\\B#\\w*[a-zA-Z]+\\w*', '', regex=True)\n",
    "# Removing numbers from all the tweets\n",
    "trained['text'] = trained['text'].str.replace('\\d+', '', regex=True)\n",
    "\n",
    "# Loop through special characters and remove them from all the tweets\n",
    "for char in special_chars:\n",
    "    trained['text'] = trained['text'].str.replace(char, '', regex=True)\n",
    "\n",
    "# Removing hyperlinks from all the tweets\n",
    "test['text'] = test['text'].str.replace(r'http?://[^\\s<>\"]+|www\\.[^\\s<>\"]+', '', regex=True)\n",
    "# Removing usernames from all the tweets\n",
    "test['text'] = test['text'].str.replace('@[A-Za-z0-9]+', '', regex=True)\n",
    "# Removing hashtags, including the text, from all the tweets\n",
    "test['text'] = test['text'].str.replace(r'\\B#\\w*[a-zA-Z]+\\w*', '', regex=True)\n",
    "# Removing numbers from all the tweets\n",
    "test['text'] = test['text'].str.replace('\\d+', '', regex=True)\n",
    "\n",
    "# Loop through special characters and remove them from all the tweets\n",
    "for char in special_chars:\n",
    "    test['text'] = test['text'].str.replace(char, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>plus added commercials experience tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>today must mean need take another trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>really aggressive blast obnoxious entertainme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               text\n",
       "0   neutral                                               said\n",
       "1  positive            plus added commercials experience tacky\n",
       "2   neutral             today must mean need take another trip\n",
       "3  negative   really aggressive blast obnoxious entertainme...\n",
       "4  negative                               really big bad thing"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>phl btv today made deplane its sunday know ma...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>things nondelayed flights na get shit togethe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>todayno reason  anyone approve merger other a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>look better service</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>customer service philly deplorable rude  unpr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               text  Predicted\n",
       "0  negative   phl btv today made deplane its sunday know ma...        NaN\n",
       "1  negative   things nondelayed flights na get shit togethe...        NaN\n",
       "2  negative   todayno reason  anyone approve merger other a...        NaN\n",
       "3   neutral                                look better service        NaN\n",
       "4  negative   customer service philly deplorable rude  unpr...        NaN"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Unique Words in Training = 11601\n",
      "Length of Unique Words in Test = 1144\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store unique words in the training data\n",
    "unique_word_in_training = []\n",
    "# Loop over each index in the \"text\" column of the \"trained\" dataframe\n",
    "for unique_word in range(len(trained['text'])):\n",
    "    # Split the current text into a list of words\n",
    "    temp = trained['text'][unique_word].split(\" \")\n",
    "    # Loop over each word in the list of words\n",
    "    for j in temp:\n",
    "        # If the current word is not already in the list of unique words\n",
    "        if j not in unique_word_in_training:\n",
    "            # Add the current word to the list of unique words\n",
    "            unique_word_in_training.append(j)\n",
    "# Print the list of unique words in the training data and the number of unique words\n",
    "\n",
    "print(f\"Length of Unique Words in Training = {len(unique_word_in_training)}\")\n",
    "# print(f\"Unique Words in Training = {unique_word_in_training}\")\n",
    "\n",
    "# Create an empty list to store unique words in the test data\n",
    "unique_word_in_test = []\n",
    "# Loop over each index in the \"text\" column of the \"test\" dataframe\n",
    "for unique_word in range(len(test['text'])):\n",
    "    # Split the current text into a list of words\n",
    "    temp = test['text'][unique_word].split(\" \")\n",
    "    # Loop over each word in the list of words\n",
    "    for j in temp:\n",
    "        # If the current word is not already in the list of unique words\n",
    "        if j not in unique_word_in_test:\n",
    "            # Add the current word to the list of unique words\n",
    "            unique_word_in_test.append(j)\n",
    "# Print the list of unique words in the test data and the number of unique words\n",
    "\n",
    "print(f\"Length of Unique Words in Test = {len(unique_word_in_test)}\")\n",
    "# print(f\"Unique Words in Test = {unique_word_in_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 2D arrays for the frequency of each unique word in the training and test data sets\n",
    "trained_2D = []\n",
    "test_2D = []\n",
    "\n",
    "# Looping through the 'text' column of the training set and the test set\n",
    "for text in trained['text']:\n",
    "    frequency = []\n",
    "    word = text.split(\" \")\n",
    "    # Looping through the unique words in the training set\n",
    "    for i in unique_word_in_training:\n",
    "        frequency.append(word.count(i))\n",
    "    trained_2D.append(frequency)\n",
    "\n",
    "for text in test['text']:\n",
    "    frequency = []\n",
    "    word = text.split(\" \")\n",
    "    # Looping through the unique words in the training set\n",
    "    for i in unique_word_in_training:\n",
    "        frequency.append(word.count(i))\n",
    "    test_2D.append(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Matrix Dimensions: (14131, 11601)\n",
      "Test Matrix Dimensions: (314, 11601)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Trained Matrix Dimensions: ({len(trained_2D)}, {len(trained_2D[0])})\")\n",
    "print(f\"Test Matrix Dimensions: ({len(test_2D)}, {len(test_2D[0])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dists = (314, 14131)\n"
     ]
    }
   ],
   "source": [
    "# Computing the Euclidean distance between each row in the test_2D and trained_2D arrays\n",
    "dists = cdist(test_2D, trained_2D, 'euclidean') \n",
    "\n",
    "# Printing the distance matrix for each row in the test set\n",
    "# for i in dists:\n",
    "#     print(dists)\n",
    "\n",
    "# Printing the shape of the distance matrix\n",
    "print(f\"Shape of Dists = {dists.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_sort(data, column_index):\n",
    "    # Check if the data has only one element or less\n",
    "    if len(data) <= 1:\n",
    "        return data\n",
    "    else:\n",
    "        # Choose the first element as the pivot\n",
    "        pivot = data[0][column_index]\n",
    "        left = []\n",
    "        right = []\n",
    "        # Split the data into left and right lists\n",
    "        for i in range(1, len(data)):\n",
    "            if data[i][column_index] < pivot:\n",
    "                left.append(data[i])\n",
    "            else:\n",
    "                right.append(data[i])\n",
    "        # Recursively sort the left and right lists and concatenate them\n",
    "        return quick_sort(left, column_index) + [data[0]] + quick_sort(right, column_index)\n",
    "\n",
    "def index_sort(lst):\n",
    "    indexed_list = []\n",
    "    # Add each element of the list with its index to a new indexed_list\n",
    "    for index, element in enumerate(lst):\n",
    "        indexed_list.append((index, element))\n",
    "\n",
    "    # Sort the indexed_list using quick_sort and column 1 as the sort key\n",
    "    sorted_list = quick_sort(indexed_list, 1)\n",
    "    result = []\n",
    "    # Extract the indexes from the sorted indexed_list and add them to the result list\n",
    "    for i in sorted_list:\n",
    "        result.append(i[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(lst):\n",
    "    # Create an empty dictionary to keep track of counts\n",
    "    temp = {}\n",
    "    \n",
    "    # Iterate through each element in the list\n",
    "    for i in lst:\n",
    "        # If the element is not already in the dictionary, add it with a count of 1\n",
    "        if i not in temp:\n",
    "            temp[i] = 1\n",
    "        # If the element is already in the dictionary, increment its count by 1\n",
    "        else:\n",
    "            count = temp[i] + 1\n",
    "            temp[i] = count\n",
    "    \n",
    "    # Initialize variables to keep track of the maximum count and the element(s) associated with that count\n",
    "    maxim = 0\n",
    "    label_maxim = []\n",
    "    \n",
    "    # Iterate through each element in the dictionary\n",
    "    for i in temp:\n",
    "        # If the count of the element is greater than the current maximum, update the maximum and the associated element(s)\n",
    "        if temp[i] > maxim:\n",
    "            maxim = temp[i]\n",
    "            label_maxim = i\n",
    "    \n",
    "    # Return the element(s) associated with the maximum count as the mode(s) of the list\n",
    "    return label_maxim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that initializes two pandas dataframes: one for a confusion matrix, and one to keep track of the frequency of predicted labels for each true label\n",
    "def init_cmatrix_testfreqdf():\n",
    "    \n",
    "    # Create an empty dataframe with rows and columns labeled according to the possible gold and predicted labels\n",
    "    cmatrix = pd.DataFrame({'Gold Positive': '', 'Gold Neutral': '', 'Gold Negative': ''},\n",
    "                        index = ['Predicted Positive','Predicted Neutral','Predicted Negative'])\n",
    "    \n",
    "    # Create an empty dataframe with rows and columns labeled according to the possible gold and predicted labels, and with an additional column for the frequency of each combination of labels\n",
    "    testfreqdf = pd.DataFrame({\"Sentiment\": '', \"Predicted\": '', \"Frequency\": ''}, index = [0,1,2,3,4,5,6,7,8])\n",
    "    \n",
    "    # Initialize a counter variable to keep track of the index of the testfreqdf dataframe\n",
    "    count = 0\n",
    "    \n",
    "    # Loop over all possible combinations of gold and predicted labels\n",
    "    for i in ['negative','neutral','positive']:\n",
    "        for j in ['negative','neutral','positive']:\n",
    "            # Set the \"Sentiment\" and \"Predicted\" columns of the current row in the testfreqdf dataframe to the current combination of labels\n",
    "            testfreqdf['Sentiment'][count] = i\n",
    "            testfreqdf['Predicted'][count] = j\n",
    "            # Set the \"Frequency\" column of the current row in the testfreqdf dataframe to 0\n",
    "            testfreqdf['Frequency'][count] = 0\n",
    "            # Increment the counter variable\n",
    "            count += 1\n",
    "    \n",
    "    # Set the index of the testfreqdf dataframe to be a MultiIndex based on the \"Sentiment\" and \"Predicted\" columns\n",
    "    testfreqdf.set_index(['Sentiment', 'Predicted'], inplace=True)\n",
    "\n",
    "    # Return both the cmatrix and testfreqdf dataframes\n",
    "    return cmatrix, testfreqdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(k, test_2D, dists, cmatrix, testfreqdf):\n",
    "    # Print statement indicating the current value of K.\n",
    "    print(\"Running For: k =\", k)\n",
    "    # Initialize a row counter.\n",
    "    row = 0\n",
    "\n",
    "    # Iterate through the distances list.\n",
    "    for lst in dists:\n",
    "        # Sort the list in ascending order and get the K nearest neighbors.\n",
    "        sorted_list = index_sort(lst)\n",
    "        knn_result = sorted_list[:k]\n",
    "        \n",
    "        # Extract the labels of the K nearest neighbors.\n",
    "        label_knn = []\n",
    "        for j in knn_result:\n",
    "            label = trained['Sentiment'][j]\n",
    "            label_knn.append(label)\n",
    "        \n",
    "        # Calculate the mode of the labels.\n",
    "        max_label = mode(label_knn)\n",
    "        \n",
    "        # Assign the predicted label to the corresponding row in the test data.\n",
    "        test['Predicted'][row] = max_label\n",
    "        \n",
    "        # Save the test data to a CSV file.\n",
    "        test.to_csv('./Datasets/Answered_Tweets_Test.csv', index=False)\n",
    "        \n",
    "        # Increment the row counter.\n",
    "        row += 1\n",
    "\n",
    "    # Calculate the frequency of each combination of actual and predicted labels.\n",
    "    temp = test.groupby([\"Sentiment\", \"Predicted\"]).size().reset_index(name=\"Frequency\")\n",
    "    temp.set_index(['Sentiment', 'Predicted'], inplace=True)\n",
    "\n",
    "    # Update the test frequency DataFrame with the new data.\n",
    "    testfreqdf.update(temp)\n",
    "\n",
    "    # Reset the index of the DataFrame.\n",
    "    testfreqdf.reset_index(inplace=True)\n",
    "\n",
    "    # Update the confusion matrix with the new frequency data.\n",
    "    cmatrix['Gold Negative']['Predicted Negative'] = testfreqdf['Frequency'][0]\n",
    "    cmatrix['Gold Negative']['Predicted Neutral'] = testfreqdf['Frequency'][1]\n",
    "    cmatrix['Gold Negative']['Predicted Positive'] = testfreqdf['Frequency'][2]\n",
    "    cmatrix['Gold Neutral']['Predicted Negative'] = testfreqdf['Frequency'][3]\n",
    "    cmatrix['Gold Neutral']['Predicted Neutral'] = testfreqdf['Frequency'][4]\n",
    "    cmatrix['Gold Neutral']['Predicted Positive'] = testfreqdf['Frequency'][5]\n",
    "    cmatrix['Gold Positive']['Predicted Negative'] = testfreqdf['Frequency'][6]\n",
    "    cmatrix['Gold Positive']['Predicted Neutral'] = testfreqdf['Frequency'][7]\n",
    "    cmatrix['Gold Positive']['Predicted Positive'] = testfreqdf['Frequency'][8]\n",
    "\n",
    "    # Print the confusion matrix.\n",
    "    print(cmatrix)\n",
    "        \n",
    "    # Calculate the True Positives, True Negatives, False Positives, and False Negatives.\n",
    "    True_Positive = cmatrix['Gold Positive']['Predicted Positive']\n",
    "    True_Neutral = cmatrix['Gold Neutral']['Predicted Neutral']\n",
    "    True_Negative = cmatrix['Gold Negative']['Predicted Negative']\n",
    "    False_Positive = cmatrix['Gold Positive']['Predicted Neutral'] + cmatrix['Gold Positive']['Predicted Negative']\n",
    "    False_Neutral = cmatrix['Gold Neutral']['Predicted Negative'] + cmatrix['Gold Neutral']['Predicted Positive']\n",
    "    False_Negative = cmatrix['Gold Negative']['Predicted Neutral'] + cmatrix['Gold Negative']['Predicted Positive']\n",
    "\n",
    "\n",
    "    # Calculating Accuracy, Precision, Recall, and F1 scores:\n",
    "    Accuracy = ((True_Positive + True_Neutral + True_Negative) / (True_Positive + True_Neutral + True_Negative + False_Positive + False_Negative + False_Neutral)) * 100\n",
    "\n",
    "    #Positive Class\n",
    "    Precision_Positive = True_Positive / (True_Positive + False_Positive)\n",
    "    Recall_Positive = True_Positive / (True_Positive + False_Negative)\n",
    "    F1_Score_Positive = 2 * (Precision_Positive * Recall_Positive) / (Precision_Positive + Recall_Positive)\n",
    "\n",
    "    # Neutral Class\n",
    "    Precision_Neutral = True_Neutral / (True_Neutral + False_Neutral)\n",
    "    Recall_Neutral = True_Neutral / (True_Neutral + False_Positive + False_Negative)\n",
    "    F1_Score_Neutral = 2 * (Precision_Neutral * Recall_Neutral) / (Precision_Neutral + Recall_Neutral)\n",
    "\n",
    "    # Negative Class\n",
    "    Precision_Negative = True_Negative / (True_Negative + False_Negative)\n",
    "    Recall_Negative = True_Negative / (True_Negative + False_Positive + False_Neutral)\n",
    "    F1_Score_Negative = 2 * (Precision_Negative * Recall_Negative) / (Precision_Negative + Recall_Negative)\n",
    "\n",
    "    # Calculating Macro-Averages:\n",
    "    Precision = (Precision_Positive + Precision_Neutral + Precision_Negative) / 3\n",
    "    Recall = (Recall_Positive + Recall_Neutral + Recall_Negative) / 3\n",
    "    F1_Score = (F1_Score_Positive + F1_Score_Neutral + F1_Score_Negative) / 3\n",
    "    \n",
    "    print(f\"\\nValue of k = {k}\")\n",
    "    print(f\"Accuracy = {round(Accuracy, 2)}%\")\n",
    "    print(f\"Precision = {round(Precision, 2)}\")\n",
    "    print(f\"Recall = {round(Recall, 2)}\")\n",
    "    print(f\"F1 Score = {round(F1_Score, 2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running For: k = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EAM\\AppData\\Local\\Temp\\ipykernel_4920\\3347482628.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Predicted'][row] = max_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Gold Positive Gold Neutral Gold Negative\n",
      "Predicted Positive             8            4            15\n",
      "Predicted Neutral              5           15           100\n",
      "Predicted Negative             4           10           153\n",
      "\n",
      "Value of k = 1\n",
      "Accuracy = 56.05%\n",
      "Precision = 0.52\n",
      "Recall = 0.35\n",
      "F1 Score = 0.33\n",
      "\n",
      "Running For: k = 3\n",
      "                   Gold Positive Gold Neutral Gold Negative\n",
      "Predicted Positive           8.0          2.0           9.0\n",
      "Predicted Neutral            9.0         23.0         131.0\n",
      "Predicted Negative             0          4.0         128.0\n",
      "\n",
      "Value of k = 3\n",
      "Accuracy = 50.64%\n",
      "Precision = 0.58\n",
      "Recall = 0.36\n",
      "F1 Score = 0.32\n",
      "\n",
      "Running For: k = 5\n",
      "                   Gold Positive Gold Neutral Gold Negative\n",
      "Predicted Positive             8            3             7\n",
      "Predicted Neutral              7           21           142\n",
      "Predicted Negative             2            5           119\n",
      "\n",
      "Value of k = 5\n",
      "Accuracy = 47.13%\n",
      "Precision = 0.55\n",
      "Recall = 0.35\n",
      "F1 Score = 0.29\n",
      "\n",
      "Running For: k = 7\n",
      "                   Gold Positive Gold Neutral Gold Negative\n",
      "Predicted Positive          11.0          5.0          11.0\n",
      "Predicted Neutral            6.0         19.0         147.0\n",
      "Predicted Negative             0          5.0         110.0\n",
      "\n",
      "Value of k = 7\n",
      "Accuracy = 44.59%\n",
      "Precision = 0.57\n",
      "Recall = 0.35\n",
      "F1 Score = 0.29\n",
      "\n",
      "Running For: k = 9\n",
      "                   Gold Positive Gold Neutral Gold Negative\n",
      "Predicted Positive          10.0          4.0          10.0\n",
      "Predicted Neutral            7.0         21.0         154.0\n",
      "Predicted Negative             0          4.0         104.0\n",
      "\n",
      "Value of k = 9\n",
      "Accuracy = 42.99%\n",
      "Precision = 0.57\n",
      "Recall = 0.35\n",
      "F1 Score = 0.28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cmatrix, testfreqdf = init_cmatrix_testfreqdf()\n",
    "KNN(1, test_2D, dists, cmatrix, testfreqdf)\n",
    "cmatrix, testfreqdf = init_cmatrix_testfreqdf()\n",
    "KNN(3, test_2D, dists, cmatrix, testfreqdf)\n",
    "cmatrix, testfreqdf = init_cmatrix_testfreqdf()\n",
    "KNN(5, test_2D, dists, cmatrix, testfreqdf)\n",
    "cmatrix, testfreqdf = init_cmatrix_testfreqdf()\n",
    "KNN(7, test_2D, dists, cmatrix, testfreqdf)\n",
    "cmatrix, testfreqdf = init_cmatrix_testfreqdf()\n",
    "KNN(9, test_2D, dists, cmatrix, testfreqdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "\n",
    "1. Damarta, R., Hidayat, A., & Abdullah, A. S. (2021). The application of k-nearest neighbors classifier for sentiment analysis of PT PLN (Persero) twitter account service quality. Journal of Physics: Conference Series, 1722(1), 012002. https://doi.org/10.1088/1742-6596/1722/1/012002\n",
    "\n",
    "2. Dutta Das, D., Sharma, S., Natani, S., Khare, N., & Singh, B. (2017). Sentimental Analysis for Airline Twitter data. IOP Conference Series: Materials Science and Engineering, 263, 042067. https://doi.org/10.1088/1757-899x/263/4/042067\n",
    "\n",
    "3. Fang, X., & Zhan, J. (2015). Sentiment analysis using product review data. Journal of Big Data, 2(1). https://doi.org/10.1186/s40537-015-0015-2\n",
    "\n",
    "4. Uddin, S., Haque, I., Lu, H., Moni, M. A., & Gide, E. (2022). Comparative performance analysis of K-nearest neighbour (KNN) algorithm and its different variants for disease prediction. Scientific Reports, 12(1). https://doi.org/10.1038/s41598-022-10358-x\n",
    "\n",
    "#### Dataset Used:\n",
    "5. Twitter US Airline Sentiment. (n.d.). www.kaggle.com. https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
